# aws-sam-api-proxy üöÄ

User and advocate of [SAM](https://github.com/awslabs/serverless-application-model)?

Buckle up and improve development of Lambdas and API Gateways... Execute your HTTP requests locally without experiencing **cold starts** and taking advantage of **context reusability**!

Spin up a local server for your API, any request will be redirected to the expected lambda according to the received path and method.

## Features

- No cold starts on every request
  - first request to an endpoint might take more than one second
  - subsequent requests are as fast as your code! üèÉ‚Äç‚ôÇÔ∏è
- Context reutilization
- Automatic discoverability of your Lambda functions
  - Global CodeUri, Runtime and Handlers are supported
  - Environment variables are passed through and can be overridden with `--env-vars`
  - All runtimes are supported
- Path parameters, querystring, body and headers are all passed through the request, with no changes
- Always watching your distribution folder - rebuild your code and changes are propagated immediately
- Already supports Http Apis

## Motivation

Developing AWS Lambdas and API Gateways locally is not usually the best experience.

I tend to develop with the help of unit tests but it just isn't enough. I always feel the need to make HTTP requests to properly test my template and code.

When I use `sam local invoke` or `sam local start-api`, even with the `--skip-pull-image` option, the cold starts on every request kills my mood and slows me down.

Another issue me and my team face, is that our APIs are behind a GraqhQL server. A query that should take less than a second to fulfil, takes about 6 to 7 seconds ü§®üî´

With this tool all this pain went away and I'm able to test my APIs much faster üòç

I hope somehow this tool is of any help to you. If you find a bug just open an issue or go ahead and fix it.

## Requirements

The only dependency to use this CLI is docker. Make sure it's running.

## CLI

### Install

```bash
npm i aws-sam-api-proxy -g
```

### Start API

Nice and easy:

```bash
cd ~/my-api
sam-proxy start my-api --port 3000
```

Or, with all the options available:

```bash
sam-proxy start my-api --port 3000 --base-path ~/my-api --template template.yaml --env-vars envVars.json --docker-network my_network
```

### Tearing down the house

#### For a specific API

```bash
sam-proxy teardown my-api
```

#### For all APIs

```bash
sam-proxy teardown-all
```

### More

```bash
sam-proxy --help
```

### Running multiple APIs

If you pretend to run multiple APIs, the only detail to take in consideration is the port you run your server on.

Why? All containers created by this tool will expose a port that is based on the server port.

Example:

Imagine your API has 4 endpoints and your server is running at port 3000.

4 containers are running, the following ports are being used: 3001, 3002, 3003 and 3004.

What you need to do, on the subsequent server, is to select an higher port. For this example, 3005 would be enough.

## Template sample

My templates usually look something like this:

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Description: Resources API
Transform: AWS::Serverless-2016-10-31

Parameters:
  Env:
    Type: String
    AllowedValues:
      - dev
      - stg
      - prd

Globals:
  Function:
    Runtime: nodejs12.x
    MemorySize: 256
    Timeout: 10
    Environment:
      Variables:
        NODE_ENV: !Ref Env

Resources:
  GetResources:
    Type: AWS::Serverless::Function
    Properties:
      CodeUri: ./dist
      Handler: GetResourcesHandler.default
      Events:
        GetResourcesEvent:
          Type: Api
          Properties:
            Path: /resources
            Method: GET
```

## Under the hood

Very succinctly, this tool does the following:

1. Parse your SAM template and your environment variables file if provided
2. Filter all functions triggered by Api or HttpApi events
3. Remove containers running for this API
4. Pull necessary docker images
5. Create and start containers for each Lambda function with the given environment variables
6. Spins up a server that acts as an API Gateway, redirecting each request to the expected container

## Logs

This server will automatically log requests details and responses status code and duration.

If you want to check the logs of a function, just take a peek at the container logs:

```bash
docker ps
docker logs get_resources_lambda
```

## Credits

This tool wouldn't be possible without [lambci/docker-lambda](https://github.com/lambci/docker-lambda) or [dockerode](https://github.com/apocas/dockerode). Thank you üçª.

## Roadmap

- Setup CI/CD
- Refactor buildContainerOptions.js to serverlessFunctions folder
- Support JSON template
- Log levels
- Lambda timeouts
- Lambda memory size
- Fill events missing data:
  - requestContext
  - multiValueHeaders
  - multiValueQueryStringParameters
  - cookies
  - stageVariables
